{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - GOT Snapchat Filter?\n",
    "## GOT Snapchat Filter?\n",
    "Making cool face filters for GOT Characters & yourself!\n",
    "In this problem, you will be building snapchat like face filters - eyeglasses and moustache for popular Game Of Throne Characters Tyrion Lannister and Jaime.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "        <img src=\"136339.svg\" alt=\"drawing\" width=\"120\"/> \n",
    "    </td>\n",
    "    <td>\n",
    "        <img src=\"136346.svg\" alt=\"drawing\" width=\"120\"/> \n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "- You will be given an input image and two image templates(one for sunglasses & moustache , you task is to overlay the eyeglasses and moustache on the given character. A sample input output is show below. To detect the facial keypoints like position of eyes and nose, we also provide you with haarcascade xml files in the training data. \n",
    "\n",
    "<img src = 'jamie.jpg' width = \"200\"/>\n",
    "\n",
    "### Bonus -\n",
    "Try to place these filters in LIVE stream taken from your webcam and display it :)\n",
    "\n",
    "### Submission Format\n",
    "For the given input image, submit a CSV file where each ith row contains the BGR pixel values for the ith pixel of modified image.\n",
    "\n",
    "### Scoring\n",
    "Total score will be based upon percentage of pixel values correctly predicted. You should flatten the image into shape(-1,3) before creating CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Data/Test/Before.png')\n",
    "glasses = cv2.imread('Data/Train/glasses.png', -1)\n",
    "mustache = cv2.imread('Data/Train/mustache.png', -1)\n",
    "eye_cascade = cv2.CascadeClassifier('frontalEyes35x16.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "nose_cascade = cv2.CascadeClassifier('Data/Train/third-party/Nose18x15.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the face detected\n",
    "for (x, y, w, h) in faces:\n",
    "\n",
    "    # create two Regions of Interest.\n",
    "    #cv2.rectangle(image,(x,y),(x+w,y+h),(255,255,0),2) \n",
    "    roi_gray = gray[y:y + h, x:x + h]\n",
    "    roi_color = image[y:y + h, x:x + h]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        #cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2) \n",
    "        roi_eyes = roi_gray[ey: ey+eh, ex: ex+ew]\n",
    "        glasses2 = image_resize(glasses.copy(), width = ew)\n",
    "        gw, gh, gc = glasses2.shape\n",
    "        \n",
    "        for i in range(0, gw):\n",
    "        \tfor j in range(0, gh):\n",
    "        \t\tif(glasses2[i, j][3] != 0):\n",
    "        \t\t\troi_color[ey + i, ex + j] = glasses2[i, j]\n",
    "\n",
    "    \n",
    "    nose = nose_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "    for (nx, ny, nw, nh) in nose:\n",
    "        #cv2.rectangle(roi_color,(nx,ny),(nx+nw,ny+nh),(120,127,255),2)\n",
    "        roi_nose = roi_gray[nx: ny+nh, nx: nx+nw]\n",
    "        mustache2 = image_resize(mustache.copy(), width = nw)\n",
    "\n",
    "        mw, mh, mc = mustache2.shape\n",
    "        for i in range(0, mw):\n",
    "        \tfor j in range(0, mh):\n",
    "        \t\tif( mustache2[i, j][3] != 0):\n",
    "        \t\t\troi_color[ny + int(nh/2.0) + i, nx+j] = mustache2[i, j]\n",
    "\n",
    "        #print(nose) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "    cv2.imshow('image', image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182845, 3)\n"
     ]
    }
   ],
   "source": [
    "image1 = image.reshape((-1, 3))\n",
    "print(image1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(image1, columns=[\"Channel 1\",\"Channel 2\",\"Channel 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
